-- Στοιχεια φοιτητων --

Ανδρεας κοκκορας sdi2000085

Νικος μιχαλουτσος sdi2000133

Τροπος μεταγλωτισης lsh: make lsh ή g++ -o lsh lsh.cpp lsh_func.cpp generals.cpp
Τροπος μεταγλωτισης cube: make cube ή g++ -o cube cube.cpp lsh_func.cpp generals.cpp
Τροπος μεταγλωτισης cluster: make cluster ή g++ -o cluster cluster.cpp cluster_func.cpp cube_func.cpp lsh_func.cpp generals.cpp
Τροπος μεταγλωτισης graph_search: make graph_search ή g++ -pthread -o graph_search graph_search.cpp graph_search_func.cpp generals.cpp lsh_func.cpp

------------------------------------------------------------------------- Εργασια 3 ----------------------------------------------------------------------------------------

Ερωτηματα που εγιναν: Α, Β.

Τα προγραμματα δεχονται ως εισοδο πλεον τα encoded αρχεια! ΟΧΙ τα κανονικα.

-- Περιγραφη προγραμματος --
- Το προγραμμα αυτο εχει στοχο τη διανυσματικη αναπαρασταση εικονας σε χωρο χαμηλοτερης διαστασης με τη χρηση αυτοκωδικοποιητη, κι υστερα την συγκριση αποστασεων και συσταδοποιηση των διανυσματων. Το προγραμμα με python φτιαχνει εναν αυτοκωδικοιητη. Και πλεον προσαρμοζει τα προγραμματα ευρεσης κοντινοτερου γειτονα με διαφορες μεθοδους στο να λειτουργουν κι αυτα στη χαμηλοτερη διασταση του αυτοκωδικοποιητη.

-- Αρχεια κωδικα και περιγραφη τους --
reduce.py: Με tensorflow και keras και την βοηθεια των νευρωνικων δικτυων χτιζει εναν αποκωδικοποιητη για την αναπαρασταση των εικονων σε 10 διαστασεις.

-- Πειραματα --
Ο αποκωδικοποιητης εχει βελτιστοποιηθει υστερα απο πειραματα με διαφορες εκδοχες του. Αρχικα παρατηρηθηκε οτι η relu ηταν πραγματι, η καλυτερη επιλογη για το προγραμμα μας και το Convolution, συμφωνα με τα αποτελεσματα του validation loss. Τα 5 epochs αποδειχθηκαν αρκετα για την αναπαρασταση των εικονων. Δοκιμαστηκαν 2, 3, 4, 5, 7 και 9 epochs. Θεωρησα οτι τα 5 epochs ειναι αρκετα για την συγκεκριμενη περιπτωση. Το batch size ειναι στα 128 υστερα απο πειραματα με δοκιμαστικα 128, 256, 512, 640, 1000, 2000 και 2500. Θεωρηθηκε οτι το 128 ηταν ιδανικο λογω των αποτελεσματων στο σφαλμα. Το shuffle στο fit() φανηκε να βελτιωνει το training process ισως επειδη απετρεπε το νευρωνικο δικτυο να μαθει με βαση την σειρα των εικονων, το οποιο θα εκανε χειροτερα τα predictions του. Επιλεχθηκε 10% των δεδομενων για testing για να επιβεβαιωσουμε οτι το σφαλμα ελαχιστοποιειται χρησιμοποιωντας optimizer την adam εφοσον παρατηρηθηκε οτι ηταν η καλυτερη σε συνδιασμο με την mean_squared_error loss function.

10 διαστασεις φαινεται να αρκουν για την προσεγγιση πλησιεστερων γειτονων σε ενα dataset οπως αυτο, συμφωνα με τους αλγοριθμους. Αλλοι λειτουργησαν καλυτερα οπως ο MRNG κι αλλοι οχι τοσο καλα οπως ο LSH.

------------------------------------------------------------------------- Εργασια 2 ----------------------------------------------------------------------------------------

-- Περιγραφη προγραμματος --
- Το προγραμμα αυτο στοχο εχει την εφαρμογη των αλγοριθμων GNNS, MRNG για κατασκευη γραφων ευρεσης κοντινοτερου γειτονα και του αλγοριθμου Search On Graph για την αναζητηση κοντινοτερου γειτονα σε γραφο, σε δεδομενα που στη συγκεκριμενη περιπτωση ειναι εικονες, απεικονισμενες ως διανυσματα. Το προγραμμα δημιουργει εναν γραφο οπου το καθε image αναπαριστα εναν κομβο και αρχιζοντας απο εναν κομβο συμφωνα με τον αλγοριθμο, βρισκει το 'κοντινοτερο' image προς το query. Ο χρηστης δινει ενα συνολο dataset κι ενα συνολο αναζητησης, το προγραμμα παιρνει μια εικονα απο το συνολο αναζητησης, εφαρμοζει μια απο τις 2 μεθοδους γραφων την οποια επιλεγει ο χρηστης και βρισκει την πιο παρομοια εικονα απο το dataset στο query. Εξαγει ενα αρχειο στο οποιο εκτυπωνεται η μεθοδος που επιλεχθηκε, οι προσεγγιστικα κοντινοτεροι γειτονες του καθε query, οι πραγματικα κοντινοτεροι γειτονες στο query, οι μεσοι οροι χρονου ευρεσης αυτων, και το μεγιστο κλασμα προσεγγισης αυτων.

GNNS: Ακολουθησαμε τις διαφανειες και απλα κατασκευαζουμε τον γραφο οπως λενε οι διαφανειες, κανοντας lsh για καθε σημειο και βαζοντας του ακμες προς τα αποτελεσματα της lsh. Υστερα κανουμε αναζητηση παλι οπως λενε οι διαφανειες, χρησιμοποιωντας vector αντι για set στο S, και βρισκοντας τον κοντινοτερο μεσω της κλασης Neibs στο τελος.

MRNG: Καναμε μικρες αλλαγες για την επιταχυνση του αλγοριθμου κατασκευης γιατι ο τροπος των διαφανειων ειναι απιστευτα αργος. Υπολογιζουμε μια φορα σε εναν πινακα τις αποστασεις του καθε σημειου με καθε αλλο πριν την κατασκευη του γραφου με optimal τροπο τοσο απο αποψης time complexity οσο και απο space complexity, ωστε να μην το υπολογιζουμε συνεχεια στην κατασκευη του γραφου. Χρησιμοποιωντας unordered_set για το Rp, και ordered_set για το Lp, υπολογιζουμε το Rp μια φορα πριν αρχισουμε την κατασκευη και του βαζουμε ολα τα σημεια ωστε να χρειαζεται μονο να του βγαζουμε προσωρινα καθε φορα τα Lp σημεια μες στην επαναληψη της κατασκευης, πετυχαινοντας λιγοτερες ενεργειες επιταχυνοντας τη μεθοδο. Οσο για την Search On Graph το l το οριζουμε ως το πληθος των στοιχειων που ελεγξαμε απο το συνολο, κι οχι το πληθος στοιχειων που βαλαμε σε αυτο (με λιγα λογια ακολουθησαμε το paper γιατι ηταν το ιδιο γρηγορο αλλα πιο αποτελεσματικο). Τελος, χρησιμοποιησαμε threads για την επιταχυνση του αλγοριθμου κι αποδειχθηκε σωστη επιλογη σε εμας.

-- Αρχεια Κωδικα και Περιγραφη τους --
- graph_search.cpp: Το αρχείο αυτό περιέχει τον κώδικα κατασκευης γραφων για την GNNS και MRNG και στη συνεχεια αλγοριθμο αναζητησης Search On Graph. Διαβαζει απο την εισοδο τα αρχεια εισοδου εξοδου και αναζητησης καθως και ορισματα τα οποια επηρεαζουν τη συμπεριφορα της αναζητησης καθος και τη μεθοδο κατασκευης γραφου κι αναζητησης. Διαβαζει το αρχειο του dataset. Φτιαχνει τον γραφο συμφωνα με την επιλεγμενη μεθοδο, και φτιαχνει και τον αρχικο κομβο αν η επιλεγμενη μεθοδος ειναι η MRNG. Υστερα ζηταει το αρχειο αναζητησης και το αρχειο εξοδου αν δεν εχει ηδη δοθει εξ αρχης. Κανει την αναζητηση με την Search on Graph αν εχει επιλεχθει η MRNG, ή με τον τροπο της GNNS κι εξαγει αποτελεσματα στο αρχειο εξοδου.

- graph_search_func.cpp: Περιεχει βοηθητικες συναρτησεις που χρησιμοποιει το graph_search.cpp, εκτος απο αυτες που χρησιμοποιουν templates, οι οποιες περιεχονται στην graph_search_func.h. Περιεχει συναρτησεις οπως την min() η οποια χρησιμοποιειται στην gnns_search(), την end_init η οποια συμβαλει στον χωρισμο του πινακα αποστασεων d της mrng σε numThreads, την getIndex() η οποια χρησιμοποιειται για να απεικονισουμε τον δισδιαστατο πινακα αποστασεων d σε μονοδιαστατο γλυτωνοντας πολυ χωρο, τις υλοποιησεις των συναρτησεων του γραφου που χρησιμοποιουμε και την set_insert που χρησιμοποιειται στην gnns_search().

- graph_search_func.h: Περιεχει τις συναρτησεις οι οποιες χρησιμοποιουν template και χρησιμοποιουνται απο την graph_search.cpp. Οι βασικοτερες ειναι η gnns_construction() για την κατασκευη του GNNS γραφου, η gnns_search() για την αναζητηση στον γραφο αυτον, η threaded mrng() οι οποια χρησιμοποιωντας threads βελτιωνει κατα πολυ τον χρονο της υψηλης σε πολυπλοκοτητα mrng() η οποια κατασκευαζει τον mrng γραφο, η search_on_graph() για την αναζητηση στον MRNG γραφο, η threaded_distances_init() η οποια χρησιμοποιωντας μαθηματικες εξισωσεις και με τη βοηθεια της end_init(), χωριζει σε δικαια τμηματα τον πινακα αποστασεων d σε threads ωστε να επιταχυνθει τη κατασκευη του, καθως και την distance_init που χρησιμοποιει καθε thread για την κατασκευη ενος μερους του πινακα d.

-- Oδηγίες χρήσης του προγράμματος --

Γινεται εισαγωγη ενος αρχειου input.dat που περιεχει εικονες αριθμητικων
ψηφιων 28*28 pixels που εχουν ακαιρεα τιμη απο 0 μεχρι 255.

Οπως και ενα αρχειο query.dat με το συνολο αναζητησης ιδιου τυπου με το input.dat.

Αρχικα ο χρηστης εισαγει το μονοπατι του dataset και μετα το μονοπατι του αρχειου αναζητησης και εξοδου, αφου το προγραμμα παραγει αποτελεσματα εχει την επιλογη να τερματισει το προγραμμα ή να επαναλαβει την αναζητηση με αλλο αρχειο, κι εχουμε δωσει και την επιπλεον επιλογη με σκετο enter να ξανατρεχει με το ιδιο αρχειο αναζητησης.

Ο χρηστης εχει την επιλογη να δωσει τρεξει το προγραμμα με τις προεπιλεγμενες τιμες των μεταβλητων που επηρεαζουν τη συμπεριφορα του προγραμματος. Μπορει ομως να δωσει τις δικες του τιμες για τις μεταβλητες R (αριθμος τυχαιων επανεκκινησεων gnns), την Ε (αριθμος επεκτασεων), την Ν (αριθμος πλησιεστερων γειτονων του αλγοριθμου), και την k (αριθμος γειτονων του καθε κομβου στον γραφο) οσο αφορα τη μεθοδο GNNS. Για τη μεθοδο MRNG μπορει να δωσει τιμες στα ορισματα k οπου παλι ειναι ο αριθμος των γειτονων του καθε κομβου στον γραφο, και του ορισματος l οπου ειναι ο αριθμος στοιχειων που θα ελεγξουμε για γειτονες στην search on graph. (Το l σε μας αναπαριστα το ποσα στοιχεια τσακαραμε απο το συνολο S κι οχι το ποσα στοιχεια βαλαμε σε αυτο. Εχουμε ακολουθησει την μεθοδο του paper κι οχι των διαφανειων διοτι ηταν πολυ πιο αποτελεσματικη).

- Τα αρχεια εισοδου και αναζητησης θα μπορουν να δινονται και μεσω παραμετρων στη γραμμη εντολων, αν οχι, τοτε ο χρηστης τα εισαγει κατα την εκτελεση του προγραμματος.
Οποτε η εκτελεση θα γινεται μεσω της εντολης:

./graph_search –d <input file> –q <query file> –k <int> -E <int> -R <int> -N <int> -l <int, only for Search-on-Graph> -m <1 for GNNS, 2 for MRNG> -ο <outputfile>

Συγκριση αλγοριθμων (Ερωτημα Γ):

Κι οι 2 αλγοριθμοι γενικοτερα βγαζουν καλα αποτελεσματα αναλογως τα ορισματα που τους δινονται. Ο καθενας εχει τα πλεονεκτηματα του και τα μειονεκτηματα του τοσο στα αποτελεσματα οσο και στον χρονο, στη χρηση πορων που απαιτουν και την απλοτητα τους.
Ο GNNS ειναι πιο γρηγορος στην κατασκευη του απο τον MRNG. Παρολα αυτα ο MRNG ειναι αναμφισβητητα πιο αποτελεσματικος αφου κατασκευαστει.

Πειραματα με GNNS:
k = 50  | E = 30 | R = 1 | N = 1 | local_optimal = false    | => MAF = 4.7
k = 50  | E = 30 | R = 1 | N = 1 | local_optimal = true     | => MAF = 5.2
k = 50  | E = 30 | R = 3 | N = 1 | local_optimal = true     | => MAF = 3.7
k = 50  | E = 30 | R = 3 | N = 1 | local_optimal = false    | => MAF = 2.9
k = 50  | E = 30 | R = 6 | N = 1 | local_optimal = true     | => MAF = 2.6
k = 50  | E = 30 | R = 6 | N = 1 | local_optimal = false    | => MAF = 2.05
k = 70  | E = 50 | R = 1 | N = 1 | local_optimal = false    | => MAF = 3.5
k = 100 | E = 50 | R = 1 | N = 1 | local_optimal = false    | => MAF = 3.7
k = 100 | E = 50 | R = 6 | N = 1 | local_optimal = false    | => MAF = 3.6
k = 40  | E = 40 | R = 10 | N = 1 | local_optimal = false    | => MAF = 1.42    | tApprox = 0.2 secs
k = 40  | E = 1 | R = 10 | N = 1 | local_optimal = false    | => MAF = 2.62     | tApprox = 0.006 secs
k = 40  | E = 1 | R = 2 | N = 1 | local_optimal = false    | => MAF = 6.6       | tApprox = 0.001 secs

Γενικοτερα οσο πιο γρηγορος ειναι τοσο μη αποτελεσματικος ειναι ο αλγοριθμος. Μπορει να επιλεξει καποιος να ειναι γρηγορος με χαμηλο αριθμο E, R, ή και k, και να μην παρει τοσο καλα αποτελεσματα. Αν ομως βαλει πιο υψηλους αριθμους και ειδικα στο R τοτε θα παρει καλυτερα. Παρολα αυτα οχι τοσο καλα οσο του MRNG. Το local optimal σε γενικες γραμμες δεν βοηθαει τις περισσοτερες φορες, αλλα επιταχυνει ελαχιστα τον αλγοριθμο καποιες φορες. Μπορει στο dataset το δικο μας να μην συμφερει κατα τη γνωμη μας αλλα ισως σε ακομη μεγαλυτερα, να φανει χρησιμο.

Πειραματα με MRNG:
k = 50  | l = 2     | => MAF = 3.48    | tApprox = 0.01 secs
k = 50  | l = 3     | => MAF = 2.75    | tApprox = 0.02 secs
k = 50  | l = 4     | => MAF = 2.75    | tApprox = 0.03 secs
k = 50  | l = 5     | => MAF = 1.20    | tApprox = 0.03 secs
k = 50  | l = 6     | => MAF = 1.12    | tApprox = 0.05 secs
k = 50  | l = 7     | => MAF = 1.08    | tApprox = 0.05 secs
k = 50  | l = 8     | => MAF = 1.00    | tApprox = 0.06 secs

Μετα το l = 8 βρισκει παντοτε τον πραγματικα κοντινοτερο γειτονα σε πολυ καλους χρονους. Αξιζει να ανεβασουμε το l στο δικο μας dataset διοτι για πολυ μικρη θυσια χρονου περνουμε πολυ καλυτερα αποτελεσματα, παρολα αυτα σε ενα μεγαλυτερο δεν γνωριζουμε κατα ποσο θα ισχυε αυτο. Αν εξερεσουμε το αρνητικο του μεγαλου χρονου κατασκευης και υψηλης χρησης πορων, ο αλγοριθμος ειναι γρηγορος και πολυ πιο αποτελεσματικος.

------------------------------------------------------------------------- Εργασια 1 ----------------------------------------------------------------------------------------

-- Περιγραφη προγραμματος --
- Το προγραμμα αυτο στοχο εχει την εφαρμογη της μεθοδου LSH knn, LSH Range Search, Hypercube knn, Hypercube Range Search σε δεδομενα οπου στην προκειμενη περιπτωση ειναι images. Το προγραμμα συγκρινει εικονες μεταξυ τους και βλεπει ποια εικονα ειναι πιο 'κοντα' στην εικονα query. Ο χρηστης δινει ενα συνολο dataset κι ενα συνολο αναζητησης, το προγραμμα παιρνει μια εικονα απο το συνολο αναζητησης, εφαρμοζει τις μεθοδους και βρισκει την πιο παρομοια εικονα απο το dataset σε αυτην. Εκτυπωνει τις εικονες αυτες που βρηκε, την 'αποσταση' της απο την query εικονα, και την αποσταση της πραγματικα κοντινοτερης εικονας ως ενδειξη της αποτελεσματικοτητας της μεθοδου. 

-- Αρχεια Κωδικα και Περιγραφη τους --
- lsh.cpp: Το αρχειο αυτο περιεχει τον κωδικα για την lsh knn και την lsh Range Search. Αρχικα διαβαζει απο την εισοδο αν εχει εισαγει ο χρηστης δεδομενα οπως ονοματα αρχειων ή τιμες μεταβλητων με τον τροπο που λεει η εκφωνηση, αλλιως χρησιμοποιει τις προεπιλογες που προτεινονται. Υστερα διαβαζει αρχειο του dataset. Φτιαχνει τη δομη αναζητησης και στη συνεχεια ζηταει το αρχειο αναζητησης και το αρχειο εξοδου. Κανει την αναζητηση με τον τροπο της LSH, τοσο του knn οσο και του Range Search, και εξαγει τα αποτελεσματα στο αρχειο εξοδου. Ελευθερωνει τη μνημη και τερματιζεται.

- cube.cpp: Το αρχειο αυτο περιεχει τον κωδικα για την hypercube knn και την hypercube Range Search. Αρχικα διαβαζει απο την εισοδο αν εχει εισαγει ο χρηστης δεδομενα οπως ονοματα αρχειων ή τιμες μεταβλητων με τον τροπο που λεει η εκφωνηση, αλλιως χρησιμοποιει τις προεπιλογες που προτεινονται. Υστερα διαβαζει αρχειο του dataset. Φτιαχνει τη δομη αναζητησης και στη συνεχεια ζηταει το αρχειο αναζητησης και το αρχειο εξοδου. Κανει την αναζητηση με τον τροπο της Hypercube knn και Range Search, και εξαγει τα αποτελεσματα στο αρχειο εξοδου. Ελευθερωνει τη μνημη και τερματιζεται.

- lsh_func.cpp: Το αρχειο αυτο περιεχει 2 συναρτησεις τις LSH μεθοδου, την h και την g. Οι συναρτησεις αυτες εχουν ως λειτουργια να παραγουν ακεραιους με καποια δεδομενα ως εισοδο.

- generals.cpp: Το αρχειο αυτο περιεχει συναρτησης γενικων χρησεων οπως η συναρτηση για την αναγνωση αρχειου readfile, η συναρτηση για υπολογισμο αποστασης k-μετρικης (dist), και μια κλαση γενικης χρησης Neibs η οποια εχει τα δικα της δεδομενα και λειτουργιες. Εκτος απο constructor/destructor η Neibs εχει μια πολυ βασικη συναρτηση insertion_sort η οποια εισαγει ταξινομημενους ακεραιους αριθμους στον πινακα nn της κλασης, και απο κει και περα εχει συναρτησης για αναγνωση δεδομενων της οπως η givenn(), givenn(int), give_size(), give_dist().

-- Oδηγίεσ χρήσης του προγράμματος --

Γινεται εισαγωγη ενος αρχειου input.dat που περιεχει εικονες αριθμητικων
ψηφιων 28*28 pixels που εχουν ακαιρεα τιμη απο 0 μεχρι 255.

Οπως και ενα αρχειο query.dat με το συνολο αναζητησης και εχει τουλαχιστον μια εικονα MNIST.

Αρχικα ο χρηστης εισαγει το μονοπατι του dataset και μετα το μονοπατι του αρχειου αναζητησης και εξοδου,
αφου το προγραμμα παραγει αποτελεσματα εχει την επιλογη η να τερματισει το προγραμμα η να επαναλαβει την αναζητηση με αλλο αρχειο.

Προαιρετικα ο χρηστης μπορει να δωσει στη γραμμη εντολων το πληθος k των lsh συναρτησεων, το πληθος L των των πινακων κατακερματισμου,
τον ακεραιο Ν των πλησιεστερων γειτωνων οπως και τον δεκαδικο R ως ακτινα αναζητησης.Διαφορετικα μενουν οι default τιμες κ=4,L=5,Ν=1,R=10000.
Ο χρηστης αμα δεν εχει δωσει τα αρχεια στη γραμμη εντολων θα τα εισαγει κατα τη διαρκεια του προγραμματος.

Επισης για τον υπερκυβο μπορει να δεινει ο χρηστης τη διασταση κ που προβαλονται τα σημεια, το μεγιστο σημειων που θα ελεχθουν Μ,
το μεγιστο πληθος κορυφων probes, ο ακεραιος N πληθος των γειτονων και ο R της ακτινας αναζητησης.Διαφορετικα μενουν οι default τιμες κ=14,Μ=10,probes=2,Ν=1,R=10000.
Ο χρηστης αμα δεν εχει δωσει τα αρχεια στη γραμμη εντολων θα τα εισαγει κατα τη διαρκεια του προγραμματος.

- Τα αρχεια εισοδου και αναζητησης θα μπορουν να δινονται και μεσω παραμετρων στη γραμμη εντολων.
Οποτε η εκτελεση θα γινεται μεσω της εντολης:

$./lsh -d <input file> -q <query file> -k <int> -L <int> -o <output file> -N
<number of nearest> -R <radious>

$./cube -d <input file> -q <query file> -k <int> -M <int> -probes <int> -o <output file> -N
<number of nearest> -R <radious>